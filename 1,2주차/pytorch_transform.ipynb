{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO9qJov2QlcJUCs6Zelb/gj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DucyAF_fWP6h","executionInfo":{"status":"ok","timestamp":1688112835472,"user_tz":-540,"elapsed":8755,"user":{"displayName":"바다","userId":"15013850930390190862"}},"outputId":"1c3b7677-aaaa-4d33-e536-f2fc86efbe50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:01<00:00, 18357922.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 361553.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:00<00:00, 6044839.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 14658708.07it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import torch\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda\n","\n","ds = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n","\n","    # transform=ToTensor(): 이미지 데이터에 적용할 변환 함수를 설정합니다.\n","    # 여기서는 ToTensor() 함수를 사용하여 이미지를 PyTorch의 Tensor로 변환합니다.\n","    # 이 함수는 이미지를 [0, 1] 범위의 값으로 정규화하고, 차원을 조정하여 채널이 첫 번째 차원에 위치하도록 변경합니다.\n","\n","    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n","\n","    # 레이블 데이터에 적용할 변환 함수를 설정합니다. 여기서는 Lambda 함수를 사용하여 레이블을 원-핫 벡터로 변환합니다.\n","    # Lambda 함수는 입력으로 받은 y 값을 사용하여 torch.zeros(10, dtype=torch.float)로 10개의 원소를 갖는 0으로 채워진 Tensor를 생성하고,\n","    # scatter_() 함수를 사용하여 해당 클래스 인덱스에 해당하는 위치에 값을 1로 설정합니다.\n",")\n","\n","# 이렇게 생성된 ds는 FashionMNIST 데이터셋의 훈련 데이터를 포함하며,\n","# 이미지는 Tensor로 변환되고, 레이블은 원-핫 벡터로 변환된 형태로 저장됩니다.\n","# 이후 이 데이터셋을 사용하여 모델을 훈련하거나 데이터를 탐색할 수 있습니다."]}]}